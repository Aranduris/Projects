{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "140de0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27e4f9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Messages = pd.read_csv(\"Messages.csv\",dtype= {\"source\": str, \"target\": str, \"Text topic 1\": float, \n",
    "                                         \"Text topic 2\": float, \"Text topic 3\": float})\n",
    "Names = pd.read_csv(\"Names.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf5c26ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Messages = Messages.dropna(axis = 0, how = 'all')\n",
    "Messages = Messages.astype(int, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0528c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_to_name = dict(zip(Names['Node #'], Names['Name']))\n",
    "# Create a new column 'source_name' and 'target_name' in Messages DataFrame\n",
    "Messages['source_name'] = Messages['source'].map(node_to_name).fillna(Messages['source'])\n",
    "Messages['target_name'] = Messages['target'].map(node_to_name).fillna(Messages['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7817008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_values(row):\n",
    "    sus = [7,11,13]  \n",
    "    if row['Text topic 1'] in sus and row['Text topic 2'] in sus and row['Text topic 3'] in sus:\n",
    "        value_combined_1 = 1\n",
    "    elif row['Text topic 1'] in sus and row['Text topic 2'] not in sus and row['Text topic 3'] in sus:\n",
    "        value_combined_1 = 1\n",
    "    elif row['Text topic 1'] in sus and row['Text topic 2'] in sus and row['Text topic 3'] not in sus:\n",
    "        value_combined_1 = 1\n",
    "    elif row['Text topic 1'] not in sus and row['Text topic 2'] in sus and row['Text topic 3'] in sus:\n",
    "        value_combined_1 = 1 \n",
    "    elif row['Text topic 1'] not in sus and row['Text topic 2'] not in sus and row['Text topic 3'] in sus:\n",
    "        value_combined_1 = 1\n",
    "    elif row['Text topic 1'] in sus and row['Text topic 2'] not in sus and row['Text topic 3'] not in sus:\n",
    "        value_combined_1 = 1\n",
    "    elif row['Text topic 1'] not in sus and row['Text topic 2'] in sus and row['Text topic 3'] not in sus:\n",
    "        value_combined_1 = 1 \n",
    "    else:\n",
    "        value_combined_1 = 0\n",
    "    \n",
    "    return value_combined_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "506d43f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Messages['Combined'] = Messages.apply(transform_values, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28c5148f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Messages[['Text topic 1', 'Text topic 2', 'Text topic 3']]\n",
    "Y = Messages['Combined']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3431f240",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3896b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones:  97\n",
      "Zeros:  303\n"
     ]
    }
   ],
   "source": [
    "count_ones = Messages['Combined'].sum()\n",
    "count_zeros = len(Messages) - count_ones\n",
    "print(\"Ones: \", count_ones)\n",
    "print(\"Zeros: \", count_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f50e2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = oversampler.fit_resample(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982c31fd",
   "metadata": {},
   "source": [
    "## Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4383b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_clf = LogisticRegression(random_state=0).fit(X_resampled, y_resampled)\n",
    "pred = log_clf.predict(X)\n",
    "prob = log_clf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b37544d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.675\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(Y, pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9dfdfb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [[0.21140468 0.0878154  0.12038467]]\n",
      "Intercept: [-1.969912]\n"
     ]
    }
   ],
   "source": [
    "# Display coefficients and intercept\n",
    "print(\"Coefficients:\", log_clf.coef_)\n",
    "print(\"Intercept:\", log_clf.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99731cf",
   "metadata": {},
   "source": [
    "## RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63fb4747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "r_clf = RandomForestClassifier(random_state=42, max_depth=7).fit(X_resampled, y_resampled)\n",
    "pred_r = r_clf.predict(X)\n",
    "prob_r = r_clf.predict_proba(X)\n",
    "accuracy = accuracy_score(Y, pred_r)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ddbbb8",
   "metadata": {},
   "source": [
    "## Adding as Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29ecc447",
   "metadata": {},
   "outputs": [],
   "source": [
    "Probabilty_of_being_sus = prob_r[:, 1]\n",
    "if 'log_weights' in Messages.columns:\n",
    "    Messages.drop('log_weights', axis=1, inplace=True)\n",
    "    Messages['log_weights'] = Probabilty_of_being_sus\n",
    "else:\n",
    "    Messages['log_weights'] = Probabilty_of_being_sus\n",
    "Messages['log_weights'] = Messages['log_weights'].replace(0, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f3434f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>Text topic 1</th>\n",
       "      <th>Text topic 2</th>\n",
       "      <th>Text topic 3</th>\n",
       "      <th>source_name</th>\n",
       "      <th>target_name</th>\n",
       "      <th>Combined</th>\n",
       "      <th>log_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kristine</td>\n",
       "      <td>Franklin</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78</td>\n",
       "      <td>3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Este</td>\n",
       "      <td>Sherri</td>\n",
       "      <td>0</td>\n",
       "      <td>0.408692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43</td>\n",
       "      <td>6</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paul</td>\n",
       "      <td>Patrick</td>\n",
       "      <td>0</td>\n",
       "      <td>0.124054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>29</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lois</td>\n",
       "      <td>Wayne</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marian</td>\n",
       "      <td>Hazel</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>42</td>\n",
       "      <td>23</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Katherine</td>\n",
       "      <td>Wesley</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>54</td>\n",
       "      <td>21</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Ulf</td>\n",
       "      <td>Alex</td>\n",
       "      <td>1</td>\n",
       "      <td>0.994615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ellin</td>\n",
       "      <td>Chris</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chris</td>\n",
       "      <td>Paige</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>67</td>\n",
       "      <td>49</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yao</td>\n",
       "      <td>Harvey</td>\n",
       "      <td>1</td>\n",
       "      <td>0.906330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     source  target  Text topic 1  Text topic 2  Text topic 3 source_name  \\\n",
       "0        19      24           4.0           NaN           NaN    Kristine   \n",
       "1        78       3          12.0           NaN           NaN        Este   \n",
       "2        43       6          10.0           NaN           NaN        Paul   \n",
       "3        45      29          15.0           NaN           NaN        Lois   \n",
       "4        26       8           6.0           NaN           NaN      Marian   \n",
       "..      ...     ...           ...           ...           ...         ...   \n",
       "395      42      23          15.0           NaN           NaN   Katherine   \n",
       "396      54      21           7.0          11.0          13.0         Ulf   \n",
       "397      68       0           1.0           NaN           NaN       Ellin   \n",
       "398       0       2          14.0           NaN           NaN       Chris   \n",
       "399      67      49           2.0           7.0           NaN         Yao   \n",
       "\n",
       "    target_name  Combined  log_weights  \n",
       "0      Franklin         0     0.010000  \n",
       "1        Sherri         0     0.408692  \n",
       "2       Patrick         0     0.124054  \n",
       "3         Wayne         0     0.010000  \n",
       "4         Hazel         0     0.010000  \n",
       "..          ...       ...          ...  \n",
       "395      Wesley         0     0.010000  \n",
       "396        Alex         1     0.994615  \n",
       "397       Chris         0     0.010000  \n",
       "398       Paige         0     0.010000  \n",
       "399      Harvey         1     0.906330  \n",
       "\n",
       "[400 rows x 9 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f5a71be",
   "metadata": {},
   "outputs": [],
   "source": [
    "Messages.to_csv('output_file.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3f0c1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.MultiDiGraph()\n",
    "# Add nodes and edges from DataFrame\n",
    "for _, row in Messages.iterrows():\n",
    "    source = row['source_name']\n",
    "    target = row['target_name']\n",
    "    # Extract weights from the DataFrame\n",
    "    weight = row['log_weights']\n",
    "    # Add edge with weights\n",
    "    G.add_edge(source, target, weight=weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2ebe9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(G, \"graph_file.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d1f0c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a graph\n",
    "#G = nx.DiGraph()\n",
    "\n",
    "# Add nodes and edges from DataFrame\n",
    "#for _, row in Messages.iterrows():\n",
    "#    source = row['source']\n",
    "#    target = row['target']\n",
    " #   G.add_edge(source, target, weight1=row['Text topic 1'], weight2=row['Text topic 2'], weight3=row['Text topic 3'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cmps530] *",
   "language": "python",
   "name": "conda-env-cmps530-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
