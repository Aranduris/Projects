---
title: "E-Sport Analytics and Predictions"
subtitle: "League of Legends"
author: "Ritwik Katiyar"
date: "November 30th 2022"
mainfont: "Times New Roman"
bibliography: references.bib
format: 
    pdf:
        documentclass: scrreprt
        pdf-math-method: katex
        cite-method: biblatex
jupyter: python3
execute:
  warning: false
  echo: false
---

---
nocite: |
  @Oracleselixirdata, @Insider, @LeagueofLegends, @WhatisLeagueofLegends, @lolesports, @worldseventviews
---
## Introduction

&nbsp;&nbsp;&nbsp;&nbsp;Currently, in e-sports one of the most highly competitive games is League of Legends (LoL). The following video link goes in greater detail about what the game is all about [What is League of Legends?](https://www.youtube.com/watch?v=BGtROJeMPeE). However, as a quick introduction League of Legends is defined as a multiplayer online battle arena (MOBA). Within league two teams of five champions (each player controlling their champion in a team of five) go head-to-head in a match to destroy the enemy nexus. Each champion has a unique set of abilities, which identifies to the champion identity to them. Moreover, there are 164 champions that a player can play. To achieve victory a team has to work together to acquire gold by killing the enemy team and dominating various objectives throughout the map. Traditionally, based on the location on the map each player is assigned a specific role, with the exception of bottom lane where there are two players. In other words, one player from the team is assigned to the top lane, mid lane, jungle and two players go to bottom lane. Often the second player in the bottom lane is referred to as support.

\begin{figure}[ht]
  \centering
  \includegraphics[width = 0.37\textwidth]{images/league_map.jpg}
  \caption{Map of Summoners Rift}
  \label{fig:Map}
\end{figure}

&nbsp;&nbsp;&nbsp;&nbsp;Every year from October to November, a World Championship event (worlds) is held where teams from different regions compete in order to win the grand prize of $2.5 million. There are 24 teams that attend worlds. This year alone a new peak viewership record was boasted by Riot Games (the company behind League of Legends) with the final game having 5.1 million live viewers.\
&nbsp;&nbsp;&nbsp;&nbsp;The worlds event is structured in multiple parts. Teams from the lower tiers first play in a qualifying tournament known as play-ins. To understand worlds we first need to understand the region tier system. If a region performed better at worlds previously then that region is given a higher tier.\
The tiers for this years world's event are as follows:

\begin{figure}[ht]
  \centering
  \includegraphics[width = 0.82\textwidth]{images/Worlds_Tiers.png}
  \caption{Tiers by Regions}
  \label{fig:Worlds}
\end{figure}
I.  China and S.Korea: Three teams from each region in the main event and one in play-ins.

II. Europe: Two teams in the main event and two in play-ins.

III.  North America: Two teams in the main event and one in play-ins.

IV. Vietnam and Pacific Championship Series (Hong Kong, Macau and Taiwan): One team from each region in the main event and in play-ins.

V.  Japan, Brazil, Australia, Latin America and Turkey: One team from each region playing in play-ins.

&nbsp;&nbsp;&nbsp;&nbsp;Only four teams qualify out of the play-ins tournament into the worlds main event. In which four groups of four teams play a double round robin (Each team in a group plays against each other twice) and the top two teams from each group advance to a single elimination, best of five games all the way to the finals. To assist with reaching the finals at the worlds event each team consists of various coaches and staff members that have an important job of drafting the champions for their players.\
&nbsp;&nbsp;&nbsp;&nbsp;Drafting champions before a game in League of Legends is an important aspect of determining if a team would win or lose. Before the game begins the players get an opportunity to pick the champions they will be playing and ban champions they wish to not play against. This is a crucial part of the game since by banning or picking away a champion the enemy player is skilled at can result in putting the enemy team at a disadvantage. Equally, picking a champion a player is skilled at can make the difference between a win and a loss. Hence, entire teams of coaching staff and data analytics spend hours compiling data to generate an optimal champion draft for their teams. Therefore, some of the most important aspects the teams pay a close attention to are the champions that were played in the past, champions that are generally banned, and champions that had a high win rate. We will be analyzing the data from worlds to get a glimpse on what champions the players would be playing at the start of the new season after worlds. By looking at champions that were highly contested or were generally considered good during the event.\
&nbsp;&nbsp;&nbsp;&nbsp;As mentioned, a key factor the coaches focus on while drafting is the player's ability to play a certain champion. If the probability of winning a game increases when a player plays a specific champion then that champion becomes a priority for the team. To mimic the team staff we will utilize a simple logistic model in order to predict what champion a player would prioritize during the champion drafting phase.\
&nbsp;&nbsp;&nbsp;&nbsp;Finally, to predict a winner before the game has occurred is a sport's analytics ultimate goal. However, making an accurate model to predict a winner can take months or years of work. Therefore, we will just be scratching the surface by generating a model that can provide predictions on a team's odds of winning based on the amount of gold a team earns. To answer the above questions we will be utilizing the data set obtained from [Oracleselixir](https://oracleselixir.com/)\
&nbsp;&nbsp;&nbsp;&nbsp;The [Oracleselixir](https://oracleselixir.com/) dataset contains end game information for every game that was played this year from January to November across all regions, across all leagues (including amateur leagues), and across all events. The information was collected by taking the end game results from [LoL Esports](https://lolesports.com/en_US/) from every region and compiling the data into one dataset. For every game the datasets first presents performance of each player per game. Then the dataset shows a cumulative team data for the two teams that played that game. This way we see the player's performance for a game, as well as, the overall team's performance. Since, the data comprises of complete end game results, it means that the data has all the end game variables and statistics that are displayed at the end of each game.\
&nbsp;&nbsp;&nbsp;&nbsp;There a total of 116 variables and 147,865 rows of observations in the data set. Therefore, to get a general idea on what the data set looks like, here are the first five rows and some of the variables from the data set:

```{python}
import pandas as pd
df = pd.read_csv("2022_LoL_esports_match_data_from_OraclesElixir_20221120.csv")
print(df.head(5))
```

## Methodology 

&nbsp;&nbsp;&nbsp;&nbsp;Considering every question is unique, we will try and answer each independently from one another with minor overlaps.The project goals we will try and accomplish are as follows:

##### Gaol-1

* Which champions had the highest pick rate?
    + Filter the data and obtain games from the worlds event. The champion columns is part of the rows that contain individual player data.
    + The champion column would need to then be aggregated on the number of times a champion was picked.
    + Then, the pick rate would be calculated by dividing the amount of times a champion was picked over the total number of games at worlds.  

* Which champions had the highest ban rate?
    + The data set would need to be filtered by the cumulative team data rows since the bans are organized by columns from ban1 to ban5. There a total of 10 bans per game and each team gets to ban 5 champions. 
    + Once the data is filtered each ban column would need to be aggregated on champions and the number of times a champion was banned.
    + Since there are 5 columns all 5 columns would need to be summed for every champion.
    + To acquire the ban rate the number of times a champion was banned would need to be divided by the total number of games.

* Which champions had the highest win rate?
    + For this part of the question we can utilize the champion data that was filtered previously for pick rate. However, we also add results from the games, where the result was a win. 
    + Then the data would need to be aggregated on champions and the number of times the champion won the game. 
    + To calculate the win rate, the champion's total wins were divided by the number of games played at worlds.

* Heat Map
    + The data from pick rate, win rate and ban rate can then be combined into one.
    + To better visualize the date and get the champions that had the highest pick rate and win rate but a low ban rate a heat map can be constructed by sorting the data as mentioned.

##### Goal-2

* Generating a model that can predict the probability of win for champions a player plays.
    + To accomplish this first the data set would need to be filtered by the individual player data as well as by regions or leagues. Considering that the top four regions are generally the one that that are most substantial at worlds it makes sense to filter the data by those regions.
    + Once the data is filtered the three variables that will be required to answer this question would be player name, champion and result.
    + Then the data would need to be filtered again by a specific player. 
    + Considering we are trying to predict the probability of a win we will need to use a logistic regression model.
    + To use a logistic regression model we will need to create dummy variables for the champions as well as the results
    + In this case our predictor would be the champions and our target variables would be the result.
    + Once the model has been constructed we would need to check if the model results are valid by find the accuracy of the model.
    + Then we can predict the probability of win for each champion and display the probability using a bar plot.  

##### Goal-3

* A Model that predicts the probability of a win based on the total gold a team earns in a game.
    + Filter the data based on the total gold earned by the team from the summer and spring splits, and the regional games should be from the top three tiers at worlds. Hence, those leagues being the LCK (Korean league), LPL (Chinese league), LCS (North American league) and LEC (The European league). This is done to insure the best quality of the data. Since lower league games are highly unpredictable and contain a lot of outliers and inconsistencies. 
    + Construct a logistic regression model for the total gold and the result columns from the filtered dataset.
    + Evaluate the model performance in order to determine if the model serves as a good predictor of wins.

## Results

```{python}
# All the libraries that will be needed
import numpy as np
import seaborn as sns
from sklearn import metrics
import plotly.express as px # This library was utilized for the plot on Page 2 of this report
import statsmodels.api as sm
import matplotlib.pyplot as plt
import statsmodels.formula.api as smf
from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression
sns.set()
```

#### Goal-1

&nbsp;&nbsp;&nbsp;&nbsp;The following plot aims to accomplish the goal of answering which champions had the highest pick rate, lowest ban rate and highest win rate at worlds?

```{python}
# Filter by games that are from the world championship
worlds_games = df[(df['league'] == "WCS")]
# Remove rows that do not have player names
individual_stats = worlds_games[(worlds_games['position'] != "team")]
# Keep the rows that have the null values as those rows are the game end stats
game_end_stats = worlds_games[(worlds_games['position'] == "team")]
# Get the amount of times a champion was picked
pick_rate = individual_stats['champion'].value_counts()
# Remove champions that were picked less than 5 times
pick_rate = pick_rate.loc[lambda x : (x >= 5)]
# Get the total number of games at worlds
total_games = len(game_end_stats)/2
# Pick rate of a champion is the number of games the champion was picked over the total number of games at worlds
pick_rate = (pick_rate/total_games)
# Get the ban rate for the ban1 column for every champion
ban_rate_1 = game_end_stats['ban1'].value_counts()
# Get the ban rate for the ban2 column for every champion
ban_rate_2 = game_end_stats['ban2'].value_counts()
# Get the ban rate for the ban3 column for every champion
ban_rate_3 = game_end_stats['ban3'].value_counts()
# Get the ban rate for the ban4 column for every champion
ban_rate_4 = game_end_stats['ban4'].value_counts()
# Get the ban rate for the ban5 column for every champion
ban_rate_5 = game_end_stats['ban5'].value_counts()
# combine all the ban rates 1-5 together into a data frame
ban_rate = pd.concat([ban_rate_1,ban_rate_2,ban_rate_3,ban_rate_4,ban_rate_5], axis=1)
# For any champion that wasn't banned in ban1-5 replace N/A into 0
ban_rate = ban_rate.fillna(0)
# Sum up the values for every champion for each ban
ban_rate = ban_rate.loc[:,'ban1'] + ban_rate.loc[:,'ban2'] + ban_rate.loc[:,'ban3'] + ban_rate.loc[:,'ban4']+ ban_rate.loc[:,'ban5']
# Remove any champion that were banned less than 5 times
ban_rate = ban_rate.loc[lambda x : (x >= 5)]
# Calculate the ban rate by dividing from the total games
ban_rate = ban_rate/total_games
# Filter the data where the result column is 1. i.e the result of the game was a win
individual_stats_win = individual_stats[(individual_stats['result'] == 1)]
# count the amount of times a champion appears
win_rate = individual_stats_win['champion'].value_counts()
# Remove champions that had less than 5 games won
win_rate = win_rate.loc[lambda x : (x >= 5)]
# Get the amount of times the champion was picked at worlds
new_pr =  individual_stats['champion'].value_counts()
# combine the two columns together
win_rate = pd.concat([win_rate,new_pr], axis=1)
# drop any values that appear as N/A
win_rate = win_rate.dropna()
# Divide column 0 (number of wins) by column 1 (Number of times a champion was picked)
win_rate = win_rate.iloc[:,0] / win_rate.iloc[:,1]
# Convert the pick_rate from a series to a data frame
picks = pick_rate.to_frame()
# Convert the index into a column
picks['Champions'] = picks.index
# drop the old index
picks.reset_index(drop=True, inplace=True)
# rename the pick rate column
picks.rename(columns={picks.columns[0]: 'pick_rate'},inplace=True)
# convert the ban_rate from a series to a data frame
bans = ban_rate.to_frame()
# convert the index into a column
bans['Champions'] = bans.index
# drop the old index
bans.reset_index(drop=True, inplace=True)
# rename the ban rate column
bans.rename(columns={bans.columns[0]: 'ban_rate'},inplace=True)
# Convert win rate series into a data frame
wins = win_rate.to_frame()
# convert the index into a column
wins['Champions'] = wins.index
# drop the old index
wins.reset_index(drop=True, inplace=True)
# Rename the win rates column as win_rate
wins.rename(columns={wins.columns[0]: 'win_rate'},inplace=True)
#Make a new merged data frame that joins the picks and bans data frames together. 
#Perform a left join in order to keep all the champions
pick_bans = pd.merge(picks, bans, on= 'Champions', how= 'left')
#Re-order the columns
pick_bans = pick_bans[['Champions', 'pick_rate', 'ban_rate']]
# Perform another merge and add wins data frame to the data frame. Perform a 
# left join in order to keep all the champions
pick_ban_win = pd.merge(pick_bans, wins, on='Champions',how='left')
# Replace any na values within win_rate column with 0.0 floating point type
pick_ban_win['win_rate'] = pick_ban_win['win_rate'].fillna(0.0)
# Replace any na values within win_rate column with 0.0 floating point type
pick_ban_win['ban_rate'] = pick_ban_win['ban_rate'].fillna(0.0)
#  convert the index into a column
pick_ban_win.index = pick_ban_win['Champions']
# sort by descending order for pick rate and win rate; Also, sort in ascending order for ban rate 
pick_ban_win = pick_ban_win.sort_values(by=['pick_rate', 'ban_rate','win_rate'] ,ascending=[False, True, False])
# take only the top 30 champions out of all the champions in the data frame
pick_ban_win = pick_ban_win.iloc[:30,1:]
# Declare a set figure size for the plot
f, ax = plt.subplots(1, 1, figsize = (8, 6.5))
# Create a list of x- axis labes for the plot
x_labs = ['Pick Rate', 'Ban Rate', 'Win Rate']
# initialize the heat map plot with the figure size
sns.heatmap(pick_ban_win,linewidths=0.5, annot=True, cbar=False,
            cmap="flare",xticklabels=x_labs, fmt="1.0%",ax=ax)
# Provide a title for the plot
plt.title('Top 30 Champions With Highest Pick,Ban and Win Rate at Worlds')
```

&nbsp;&nbsp;&nbsp;&nbsp;The above heat maps presents the top 30 champions with a high win and pick rate, but a low ban rate. Champions with high ban rates or low pick and win rates are most likely not going to see much game play at the games that will be played after worlds. However, champions like Sejuani, Sylas, Azir and Aatrox would be continued to be played. We may even see an increase in bans for Nami and Lulu since these champions seems to be demonstrating a relatively high pick and win rate with an extremely low ban rate. 

#### Goal-2

&nbsp;&nbsp;&nbsp;&nbsp;Generating a model that can predict the probability of wins for champions a player plays. In this case we will look at a player known as Zeka from the South-Korean regional league (LCK) his team; DRX won worlds this year. It would be interesting to see if the model can predict what champions Zeka prioritized at worlds. 

```{python}
#|output: asis
# player name
player_name = "Zeka"
# Getting closer's games at worlds by sorting by games he played and his performance in the games
player_at_worlds = individual_stats[(individual_stats['playername'] == player_name)]
# Just getting the champion column
player_at_worlds = player_at_worlds.loc[:,('champion')]
# Count the times the player played the champions
player_at_worlds = player_at_worlds.value_counts()
# filter the original data frame by individual player data, From the summer split
# Where the regional league is Korea,China,North America and Europe.
player_champs = df[(df['position'] != "team") &
                   ((df['split'] == "Summer")) &
                   ((df['league'] == 'LCK') | (df['league'] == 'LCS') | 
                    (df['league'] == 'LPL') | (df['league'] == 'LEC'))]
# Filter the columns that we need. That being playername, champion they played and 
# the result of the game
player_champs = player_champs.loc[:,('playername','champion','result')]
# Filter by a specific player
player = player_champs[(player_champs['playername'] == player_name)]
# Reset the index to start from 0
player.reset_index(drop=True, inplace=True)
# get the number of times a champion was played by the player
unique_champs = player['champion'].nunique()
# Get the names of all the unique champions the player plays
player_champs = player['champion'].unique()
# convert the series into a data frame of champions
player_champs = pd.DataFrame(player_champs, columns =['Champions'])
# Sort the champions by alphabetical order
player_champs = player_champs['Champions'].sort_values(ascending=True)
# Reset the index
player_champs.reset_index(drop=True, inplace=True)
# One hot encode the champions and the result columns
player = pd.get_dummies(player, columns = ['champion','result'])
# Include all the one hot encoded champions as predictors
X = player.iloc[:,1:-2]
# Include all the results where the player won as the target variable
Y = player.iloc[:,-1]
# Initialize and name the model
log_regression = LogisticRegression()
# fit the data onto the model
log_regression.fit(X,Y)
# Prints the intercept for the model
print('Intercept :', log_regression.intercept_,"\n")
# Prints the coefficient for the model
print('Coefficient: ',log_regression.coef_,"\n")
# Use the model to try and predict the results
pred = log_regression.predict(X)
```

The equation for our model can be given as:\
$$P(Win)={e^{(-0.19+0.034*{Champion_1}) + (-0.19-0.112*{Champion_2})...} \over 1+e^{(-0.19+0.034*{Champion_1}) + (-0.19-0.112*{Champion_2})...}}$$

```{python}
#|output: asis
# Generate the accuracy score of the model by constructing a confusion matrix. 
print("Accuracy Test Results for Zeka: ", round(accuracy_score(Y, pred),2))
```
&nbsp;&nbsp;&nbsp;&nbsp;From the results above we can see the intercept and coefficients for all the champions the player plays constructed by the model. We can also see the accuracy score of the model. The accuracy score is generated by computing the confusion matrix. A confusion matrix is a matrix constructed by taking the actual values and comparing them to the values predicted by the model. The accuracy represents the amount of times the model was able to predict the result correctly. Hence, the score suggests that our model is able to predict the results correctly about 65.3% of the time. The score for this player is particularly low, although after testing a number of players the accuracy score seems to range from 59% to 100%. The reason the accuracy score is low is due to the amount of different champions the player plays. Therefore, players that play fewer champions yield a higher accuracy score. If a player plays too many different champions, then there simply is not enough data for the model to be more accurate.\
&nbsp;&nbsp;&nbsp;&nbsp;For example a player named Larssen has a small pool of champions that he plays than Zeka. if we run our model on him the accuracy score should be higher. 

```{python}
#|output: asis
def larssen():
    player_name = "Larssen"
    player_champs = df[(df['position'] != "team") &
                   ((df['split'] == "Summer")) &
                   ((df['league'] == 'LCK') | (df['league'] == 'LCS') | 
                    (df['league'] == 'LPL') | (df['league'] == 'LEC'))]
    player_champs = player_champs.loc[:,('playername','champion','result')]
    player = player_champs[(player_champs['playername'] == player_name)]
    player.reset_index(drop=True, inplace=True)
    unique_champs = player['champion'].nunique()
    player_champs = player['champion'].unique()
    player_champs = pd.DataFrame(player_champs, columns =['Champions'])
    player_champs = player_champs['Champions'].sort_values(ascending=True)
    player_champs.reset_index(drop=True, inplace=True)
    player = pd.get_dummies(player, columns = ['champion','result'])
    X = player.iloc[:,1:-2]
    Y = player.iloc[:,-1]
    log_regression = LogisticRegression()
    log_regression.fit(X,Y)
    pred = log_regression.predict(X)
    return accuracy_score(Y, pred)
    
print("Accuracy test result for Larssen: ", round(larssen(),2))
```

&nbsp;&nbsp;&nbsp;&nbsp;We can see that with a smaller champion pool our model is able to perform better. Regardless, we can plot our predicted results along with the results from worlds in order to see if our model was able to provide some insight about what champions he would play at worlds. 

```{python}
#| fig-pos: 'h'
#| layout: [[40,60]]
print("\n")
# Plot the champions played by the champions
f, ax = plt.subplots(1, 1, figsize = (6, 5))
sns.barplot(x=player_at_worlds.index, y=player_at_worlds.values,ax=ax,palette ="mako")
plt.xticks(rotation=-45)
plt.xlabel("Champions")
plt.ylabel("Amount of Games Played")
plt.title('Champions played at Worlds')
# To generate the probabilities for every champion we need a new set of data
# Hence, create a numpy array of the length of champions the player plays
nparray=np.empty(unique_champs)
# Fill the array with 1's
nparray.fill(1)
# Make sure all the values are of type int and not float
nparray = nparray.astype(int)
# Convert the 1d array into a matrix with the same number of rows and columns as the array
nparray = np.diag(nparray)
# convert the matrix into a data frame
champ = pd.DataFrame(nparray)
# add the column name for the now converted matrix by using the player champs data frame
# that was processed earlier
champ.columns = X.columns
# predict the probabilities for every champion
prob = log_regression.predict_proba(champ)
# get the win probabilities only
prob = prob[:,1]
# convert the array into a data frame
prob = pd.DataFrame(prob, columns =['Probability_of_Win'])
# add champion name for each probability
prob['Champion']  = player_champs
# sort the data frame by the least probability of win on top
prob = prob.sort_values(by='Probability_of_Win',ascending=True)
# plot the probabilities as a bar plot
f, ax = plt.subplots(1, 1, figsize = (5, 3))
sns.barplot(data=prob, x="Probability_of_Win",
            y="Champion",orient="h",ax=ax,
            palette ="mako_r")
plt.xlabel("Probability of Win")
plt.title('Probability of Win Per Champion')
```

&nbsp;&nbsp;&nbsp;&nbsp;The plot on the left shows the champions played by Zeka at worlds vs. the amount of times he played each champion.The plot on the right shows the probability of win per champion as generated by the model. We can see that Zeka has a high win rate probability for Corki, Sylas, Orianna, Azir, and Swain. Looking at the plot on the left we can see he did in-fact play Azir and Sylas the most where he has a relatively high probability of win. However, he did not play champions like Orianna and Corki.

#### Goal-3

&nbsp;&nbsp;&nbsp;&nbsp;The following results aims to utilize a generated model that can predict a team's win probability by the amount of gold they earned on average in a game:
```{python}
gold = df[(df['position'] == "team") & 
          ((df['split'] == "Summer") | (df['split'] == "Spring")) & 
          ((df['league'] == 'LCK') | (df['league'] == 'LCS') | 
           (df['league'] == 'LPL')| (df['league'] == 'LEC'))]
gold = gold.loc[:,('totalgold', 'result')]
logreg_stats = smf.glm(formula = 'result ~ totalgold', data=gold, family=sm.families.Binomial()).fit()
f, ax = plt.subplots(1, 1, figsize = (4,4))
sns.regplot(x=gold['totalgold'], y=gold['result'], logistic=True, ci=None,
            scatter_kws={'color': 'black'}, line_kws={'color': 'red'},ax=ax)
plt.xticks(rotation=45)
plt.title("Logistic Regression Curve For Gold Earned vs. Probabilty of Winning")
plt.ylabel('Win (1) vs. Loss (0)')
plt.xlabel('Total Gold Earned by a Team')
```

&nbsp;&nbsp;&nbsp;&nbsp;The plot above shows the regression curve for the probability of win based on the amount of gold earned in a game. We can see the probability of win increase based on the gold; capping at 10,000 gold totals. The few dots at the bottom where a team lost with 100,000+ gold could be from a game that lasted for over 45 minutes where both teams were able to acquire a copious amounts of gold. For the model the total gold earned has a p-value of approxmatly 0.0 which means that it is a significant predictor for wins. The model's equation can be given as:\
$$P(Win)={e^{(-5.619+9.64e^{-05}*{Total_{Gold}})} \over 1+e^{(-5.619+9.64e^{-05}*{Total_{Gold}})}}$$
Confusion Matrix:
```{python}
logreg_stats_pred_prob = logreg_stats.predict()
logreg_stats_pred_class = [('0' if prob < 0.5 else '1') for prob in logreg_stats_pred_prob ]
conf_mat = metrics.confusion_matrix(gold.result.astype(str), logreg_stats_pred_class)
conf_mat = pd.DataFrame(conf_mat)
matrix_index = ['Positive', 'Negative']
conf_mat.columns = matrix_index
conf_mat.index = matrix_index
conf_mat
```
\
&nbsp;&nbsp;&nbsp;&nbsp;The above data shows the confusion matrix constructed by the matrix library. We can see that our model is predicting only 1249 wins and 1221 losses instead of 1772 wins and losses (Our filtered data set contains 1772 wins and losses). Using this we can hence calculate the accuracy of our matrix using the accuracy score library.

```{python}
#|output: asis
print("Accuracy score for the model: ", 
      round(accuracy_score(gold.result.astype(str), 
                     logreg_stats_pred_class),2),)
```

&nbsp;&nbsp;&nbsp;&nbsp;We can see that our accuracy score for the model is 70%. Furthermore, to increase the accuracy we would need to determine further variables that can significantly affect the game and give us the results we desire. As a test, we can still predict what the probability of win for a game between two teams would be by calculating the mean total gold they earn from their past games and using our model to predict the probability.

```{python}
#|class-message: false
team_1 = df[(df['position'] == "team") & 
          ((df['split'] == "Summer") | (df['split'] == "Spring")) & 
          ((df['teamname'] == 'T1'))]
team_2 = df[(df['position'] == "team") & 
          ((df['split'] == "Summer") | (df['split'] == "Spring")) & 
          ((df['teamname'] == 'JD Gaming'))]
team_1 = np.array(team_1['totalgold'].mean())
team_2 = team_2['totalgold'].mean()
team_1 = logreg_stats.predict(exog=dict(totalgold=team_1))
team_2 = logreg_stats.predict(exog=dict(totalgold=team_2))
print("Probabilty of win for T1:", team_1.values,"\n")
print("Probabilty of win for JD Gaming:", team_2.values,"\n")
```

&nbsp;&nbsp;&nbsp;&nbsp;Our model shows the probability of win for the team T1 to be 57% and the team JD Gaming to be about 53% so we can assume that T1 would win. At the worlds semi-finals game T1 vs. JD Gaming; T1 managed to get a narrow 3-2 victory in a best of five series. However, we are only looking at the individual team probability and we are not taking into consideration which team T1 was facing. For example, if we look at the similar probabilities between T1 and the team Cloud 9 we get the following:

```{python}
#|message: false
team_1 = df[(df['position'] == "team") & 
          ((df['split'] == "Summer") | (df['split'] == "Spring")) & 
          ((df['teamname'] == 'T1'))]
team_2 = df[(df['position'] == "team") & 
          ((df['split'] == "Summer") | (df['split'] == "Spring")) & 
          ((df['teamname'] == 'Cloud9'))]
team_1 = np.array(team_1['totalgold'].mean())
team_2 = team_2['totalgold'].mean()
team_1 = logreg_stats.predict(exog=dict(totalgold=team_1))
team_2 = logreg_stats.predict(exog=dict(totalgold=team_2))
print("Probabilty of win for T1:", team_1.values,"\n")
print("Probabilty of win for Cloud 9:", team_2.values,"\n")
```

&nbsp;&nbsp;&nbsp;&nbsp;We can see that the probabilities are extremely close. However, Cloud 9 has never won a game against T1 so our model is nearly failing since there is no accounting for which team a team is against. The probabilty of win for Cloud 9 should be increadibly lower compared to T1.

## Discussion

&nbsp;&nbsp;&nbsp;&nbsp;For the first question we concluded that the champions that will be most impactful after the worlds event would be Sejuani, Sylas, Azir, Aatrox, and Aphelious. Some of the champions that were undoubtedly strong but were worthy of a note were champions like Nami, Lulu, Fiora and Jax that had a low pick and ban rate.\
&nbsp;&nbsp;&nbsp;&nbsp;The second question aimed to answer if a model could be created to determine the probability of wins for a player based on the champion selected. After, using Multiple Logistic regression model our results varied from 59% to 100% accuracy based on the amount of champions the player played. Our model also lacked critical data from practice games and off stage games, with more data our model could predict with higher accuracy. Alternatively, there might be a model out there that can predict the probability with the amount of data that we have. Despite the low accuracy, our model was able to provide some insight on what champions a player would play. By looking at a player known as Zeka, we noticed that his most played champions at worlds were Sylas, Azir, and Akali. Based on the model the player's highest probability of wins were on Corki, Sylas, Orianna, Azir, Swain, Ahri, and Akali respectively. Our model was able to show that the drafting team for Zeka was focusing on getting him the champions he had high probability of winning on. We can also use our results from the first question in order to determine why he did not play Corki, Orianna, Swain, and Ahri. Considering those champions were not a priority by the teams at worlds it could be possible that the coaching staff decided to have Zeka focus on Sylas,Azir and Akali champions in order to simply deny them from the enemy. Moreoever, since he has a decent win rate with Sylas and Azir it is a relatively safe pick.\
&nbsp;&nbsp;&nbsp;&nbsp;For our final question we tried to determine the probability of win for a team. In order to determine this, we tried to simply base the probability of wins on the total amount of gold a team earns. We used logistic regression model again and were able to obtain 70% accuracy for our data set. The accuracy for our model would most likely be improved by finding other win determining factors. The high value factors can be determined by using random forest, Principle Component Analysis, and other machine learning algorithms. However, even for a low accuracy score our model is still useful and can predict wins. As an example we used it to try and predict the probability of win based on the mean total gold earned by team T1 and compared the probability to another team called JD Gaming. Since T1 had a higher probability of winning we determined that T1 would win and in fact at the worlds event the T1 managed to beat JD Gaming at the semi-finals. Considering the model is largely incomplete the model has a number of short comings. Such as the fact that the model does not take into account which team a team is playing against, champions played by the team, player's performance, other game factors such as a team's ability to obtain objectives, etc. Despite the short comings the model still has a decent accuracy for a start.\
&nbsp;&nbsp;&nbsp;&nbsp;The dataset we used for this project is massive and can be used to answer a myriad of questions about the game and the players. Due to constraints some of the questions and their results were not included in this report. These results can be viewed raw within the 'Project_playground.ipynb' file along with the report. Overall, we were successfully able to display and look at the champion's pick, win and ban rates at the worlds event. We also were able to predict what champion a player would play based on their probability of winning when playing said champion, and finally we were able to successfully set up the foundations for a model that can determine the winner before the game has been played. 